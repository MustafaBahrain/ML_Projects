# 1. Credit Scoring Model
* Description: This project builds a predictive model to assess creditworthiness and reduce credit default risks.
* Techniques Used: Logistic Regression, Random Forest, XGBoost, Data Preprocessing, Feature Engineering.
* Key Skills: SQL, Python, Model Evaluation, Feature Engineering.
* Objective: To predict whether a customer is likely to default on their credit or not, providing insights for banks and financial institutions.
# 2. Portuguese Bank Classification
* Description: A classification model predicting the likelihood of term deposit subscriptions based on customer data from a Portuguese bank.
* Techniques Used: Logistic Regression, Random Forest, Hyperparameter Tuning, Classification Metrics.
* Key Skills: SQL, Power BI, Data Exploration, Classification Modeling.
* Objective: To help banks improve customer targeting strategies for term deposit subscriptions.
# 3. Handwritten Digits Recognition (MNIST)
* Description: A deep learning project that builds a Convolutional Neural Network (CNN) to classify handwritten digits from the MNIST dataset.
* Techniques Used: CNN, Keras, Hyperparameter Tuning, Model Optimization.
* Key Skills: Deep Learning, CNN, Python, Keras.
* Objective: To recognize and classify handwritten digits using neural networks.
# 4. Heart Disease Prediction
* Description: A machine learning model that predicts the likelihood of heart disease based on health-related features.
* Techniques Used: Logistic Regression, Random Forest, SVM, Data Preprocessing.
* Key Skills: Python, Model Evaluation, Feature Engineering, Data Cleaning.
* Objective: To predict the risk of heart disease and assist in early diagnosis.
# 5. House Price Prediction
* Description: A regression model built to predict house prices using various machine learning techniques and data transformations.
* Techniques Used: Linear Regression, Decision Trees, Feature Engineering, Outlier Detection.
* Key Skills: Regression Modeling, Python, Feature Engineering, Data Analysis.
* Objective: To predict house prices based on features like location, size, and condition.
# 6. TCS Stock data - Live and Latest
* Description: A data science project focused on analyzing and predicting TCS stock prices using historical data, applying regression and time series models.
* Techniques Used: EDA & Feature Engineering Regression Models: Linear, Random Forest , Time Series Models: ARIMA, SARIMA, Prophet,Model Evaluation: MAE & RMSE.
* Key Skills: Python, pandas, scikit-learn, statsmodels, Prophet, data visualization, time series forecasting.
* Objective: To identify trends in TCS stock prices and build accurate forecasting models, recommending the best one for future predictions.
# 7. E-Commerce Furniture Dataset 2024
* Description: This project leverages a dataset scraped from AliExpress containing 2,000 furniture product listings. The goal is to understand and predict consumer buying behavior by analyzing sales trends and product features. After preprocessing and exploratory analysis, several regression models were implemented and compared to identify the best-performing model for predicting units sold. Gradient Boosting emerged as the top model.
* Techniques Used: Exploratory Data Analysis (EDA), Label Encoding & Feature Engineering, Outlier Handling & Scaling, Correlation Matrix & Feature Selection, Multiple Regression Models, Hyperparameter Tuning, Model Evaluation (MAE, MSE, RMSE, R²).
* Key Skills: Python (Pandas, NumPy, Scikit-learn, Seaborn, Matplotlib), ML Algorithms (Linear Regression, Decision Tree, KNN, SVR, XGBoost, Gradient Boosting, etc.), Model Evaluation & Comparison, Data Cleaning & Preprocessing, Presentation & Communication (PPT Creation).
* Objective: To predict the number of furniture items sold based on key product attributes like price, original price, product title, and tags using regression techniques.
# 8. Google Play Store Apps
* Description: This project provides an in-depth analysis of apps on the Google Play Store. It explores various features like ratings, reviews, app size, installs, and pricing to uncover insights into app performance and market behavior. The goal is to identify trends and patterns that can help developers, marketers, or users better understand the Android app ecosystem through data-driven exploration and visualizations.
* Techniques Used: Data Cleaning & Preprocessing, Exploratory Data Analysis (EDA), Data Visualization using Matplotlib & Seaborn, Trend & Correlation Analysis.
* Key Skills: Python, Pandas, NumPy, Matplotlib, Seaborn, Data Wrangling, Analytical Thinking.
* Objective: To analyze the characteristics of apps on the Google Play Store—such as ratings, reviews, installs, and more—to uncover trends, outliers, and patterns in the app market.
# 9. IBM HR Analytics Employee Attrition & Performance
* Description: This project focuses on predicting spare parts inventory requirements for service centers to meet Just-In-Time (JIT) inventory standards. By analyzing historical service data, we built a classification model that identifies the likelihood of part requirements, helping reduce storage costs and improve efficiency.The project combines Python for data modeling, Excel for early insights and reporting, and Power BI for advanced visualizations and dashboards.
* Techniques Used: Exploratory Data Analysis, Feature Engineering & Selection, Handling Missing Values & Outliers, Data Visualization (Matplotlib, Seaborn, Power BI, Excel), Classification Models (Random Forest, XGBoost, Logistic Regression, etc.), Model Evaluation.
* Key Skills: Python (Pandas, NumPy, Sklearn, Matplotlib, Seaborn), Excel (Formulas, Charts, Pivot Tables, Regression), Power BI (DAX, Power Query, Interactive Dashboards), Git & GitHub for version control and collaboration.
* Objective: To build a predictive model that helps service centers maintain optimal spare part inventory levels and achieve Just-In-Time (JIT) standards, minimizing overstock and understock issues.
# 10. UBER Analysis 
* Description: A machine learning project to predict Uber trip demand in NYC using TLC dispatch data. Includes EDA, feature engineering, and multiple regression models. Gradient Boosting achieved the best performance in forecasting trips.
* Techniques Used: Data Preprocessing (Handling dates, scaling, encoding), Exploratory Data Analysis (EDA), Feature Engineering (day, week, month extraction), Machine Learning Models:Linear Regression, Decision Tree, Random Forest, SVR, KNN, Bagging Regressor, Gradient Boosting, AdaBoost, Hyperparameter Tuning & Cross Validation.
* Key Skills: Python (Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn), Data Cleaning & Visualization, Regression Modeling, Model Evaluation (R², MAE, RMSE), Feature Encoding & Scaling.
* Objective: Predict daily Uber trip demand in NYC using historical dispatching data and identify trends for better resource planning.
# 11. World Population Analysis
* Description: This project aims to predict the 2022 population of countries around the world using historical population data, area, population density, growth rate, and world population percentage. Through this project, various regression algorithms were applied and compared to identify the best-performing model for accurate population forecasting. The workflow includes exploratory data analysis, data preprocessing, feature selection, model training, evaluation, and result visualization.
* Techniques Used: Exploratory Data Analysis (Univariate, Bivariate, Multivariate), Data Preprocessing (Handling missing values, outliers, encoding, scaling), Feature Selection (Correlation analysis, heatmap, multicollinearity check), Regression Modeling (Linear, Ridge, Lasso, SVR, KNN, Decision Tree, Random Forest, Gradient Boosting), Model Evaluation (MSE, MAE, R² Score), Hyperparameter Tuning & Cross-Validation, Model Comparison Visualization (Bar plots).
* Key Skills: Python (pandas, numpy, matplotlib, seaborn, scikit-learn), Machine Learning (Regression Techniques), Data Cleaning & Feature Engineering, Visualization & Interpretation of Results, Model Optimization & Evaluation.
# 12. Twitter Financial News
* Description: This project focuses on classifying financial tweets into multiple categories such as Analyst Update, Stock Movement, Financial Results, and more. The aim is to automate the understanding and tagging of financial news, aiding financial analysts and institutions in real-time sentiment analysis and decision-making.The project involves preprocessing raw text data, extracting meaningful features, applying TF-IDF vectorization, and building various classification models. After evaluating multiple algorithms, Support Vector Machine (SVM) with tuned hyperparameters was selected as the best-performing model.
* Techniques Used: Text Preprocessing (lowercasing, stopword removal, etc.), Feature Engineering (tweet length, label encoding), TF-IDF Vectorization, Supervised Classification Models, Model Tuning with GridSearchCV, Performance Evaluation (Accuracy, Comparison of models).
* Key Skills: Natural Language Processing (NLP), Scikit-learn ML algorithms, Data Cleaning and Feature Engineering, Hyperparameter Tuning, Data Visualization (matplotlib, seaborn).

